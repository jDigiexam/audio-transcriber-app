<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Transcriber (Web Speech API)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .listening-indicator {
            width: 12px;
            height: 12px;
            background-color: #ef4444; /* red-500 */
            border-radius: 50%;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800 flex items-center justify-center min-h-screen">

    <div class="bg-white rounded-xl shadow-lg p-6 sm:p-8 w-full max-w-2xl mx-4">
        <header class="text-center mb-6">
            <h1 class="text-3xl font-bold text-gray-900">Audio Transcriber</h1>
            <p class="text-gray-500 mt-1">Uses your browser's built-in speech recognition.</p>
        </header>

        <main>
            <div class="flex flex-col items-center justify-center space-y-6">
                <!-- Record Button -->
                <button id="recordButton" class="group bg-blue-600 hover:bg-blue-700 text-white rounded-full p-5 transition-all duration-300 ease-in-out shadow-md focus:outline-none focus:ring-4 focus:ring-blue-300">
                    <svg id="micIcon" xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="transition-transform duration-300 group-hover:scale-110"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="22"></line></svg>
                    <svg id="stopIcon" xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 24 24" fill="currentColor" class="hidden"><rect x="6" y="6" width="12" height="12" rx="2"></rect></svg>
                </button>
                
                <!-- Status Display -->
                <div id="status" class="h-6 text-gray-600 text-center transition-opacity duration-300">
                    Click the microphone to start transcribing
                </div>
            </div>

            <!-- Transcription Output -->
            <div id="resultContainer" class="mt-8">
                <h2 class="text-lg font-semibold text-gray-700 mb-2">Transcription:</h2>
                <div id="transcription" class="w-full bg-gray-100 p-4 rounded-lg min-h-[150px] border border-gray-200 whitespace-pre-wrap"></div>
                 <button id="copyButton" class="mt-4 bg-gray-200 hover:bg-gray-300 text-gray-700 font-medium py-2 px-4 rounded-lg transition-colors duration-200">
                    Copy Text
                </button>
            </div>
        </main>

    </div>

    <script>
        const recordButton = document.getElementById('recordButton');
        const statusDiv = document.getElementById('status');
        const transcriptionDiv = document.getElementById('transcription');
        const micIcon = document.getElementById('micIcon');
        const stopIcon = document.getElementById('stopIcon');
        const copyButton = document.getElementById('copyButton');

        let isListening = false;
        let recognition;
        
        // --- KEY CHANGE 1: State variable to hold the final transcript ---
        let finalTranscript = '';

        // Check for browser support
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.continuous = true; 
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                isListening = true;
                updateUIListening();
            };

            recognition.onend = () => {
                isListening = false;
                updateUIIdle();
            };

            recognition.onerror = (event) => {
                console.error("Speech recognition error:", event.error);
                statusDiv.innerText = `Error: ${event.error}. Please try again.`;
            };

            // --- KEY CHANGE 3: Modified logic to append text ---
            recognition.onresult = (event) => {
                let interimTranscript = '';
                // Loop through results from the current session
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        // Once a result is final, add it to our global final transcript
                        finalTranscript += transcript + ' ';
                    } else {
                        // Otherwise, it's an interim result
                        interimTranscript += transcript;
                    }
                }
                // Update the display with the cumulative final transcript and the current interim one
                transcriptionDiv.innerHTML = finalTranscript + `<span class="text-gray-500">${interimTranscript}</span>`;
            };

        } else {
            statusDiv.innerText = "Sorry, your browser doesn't support the Web Speech API. Try Chrome or Edge.";
            recordButton.disabled = true;
        }

        recordButton.addEventListener('click', () => {
            if (isListening) {
                recognition.stop();
            } else {
                // --- KEY CHANGE 2: REMOVED line that cleared the transcription div ---
                recognition.start();
            }
        });
        
        copyButton.addEventListener('click', () => {
            const textToCopy = transcriptionDiv.innerText;
            if (textToCopy) {
                const textArea = document.createElement('textarea');
                textArea.value = textToCopy;
                document.body.appendChild(textArea);
                textArea.select();
                try {
                    document.execCommand('copy');
                    copyButton.innerText = 'Copied!';
                    setTimeout(() => copyButton.innerText = 'Copy Text', 2000);
                } catch (err) {
                    console.error('Failed to copy text: ', err);
                    copyButton.innerText = 'Failed to copy';
                }
                document.body.removeChild(textArea);
            }
        });

        function updateUIListening() {
            micIcon.classList.add('hidden');
            stopIcon.classList.remove('hidden');
            recordButton.classList.remove('bg-blue-600', 'hover:bg-blue-700');
            recordButton.classList.add('bg-red-600', 'hover:bg-red-700');
            statusDiv.innerHTML = '<div class="flex items-center space-x-2 justify-center"><div class="listening-indicator"></div><span>Listening... Click to stop.</span></div>';
        }
        
        function updateUIIdle() {
            stopIcon.classList.add('hidden');
            micIcon.classList.remove('hidden');
            recordButton.classList.remove('bg-red-600', 'hover:bg-red-700');
            recordButton.classList.add('bg-blue-600', 'hover:bg-blue-700');
            statusDiv.innerText = "Click the microphone to start transcribing";
        }
    </script>

</body>
</html>

